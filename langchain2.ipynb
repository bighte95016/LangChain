{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-08GBKw9V6YPjQbuOojfI1hSWNSXO5LNKqczpX0EtbLTKnFZq'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_base=os.environ[\"CHATGPT_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 如何加載PDF和搜索網頁信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##讀取PDF資料\n",
    "loader = PyPDFLoader(\"./data/ML-guide.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#確認頁數\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearning-Lecture01  \n",
      "Instructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \n",
      "learning class. So what I wanna do today is just spend a little time going over the logistics \n",
      "of the class, and then we'll start to talk a bit about machine learning.  \n",
      "By way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \n",
      "I personally work in machine learning, and I've worked on it for about 15 years now, and \n",
      "I actually think that machine learning is the \n"
     ]
    }
   ],
   "source": [
    "#讀取第1頁前500字符訊息\n",
    "page = pages[0]\n",
    "print(page.page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/ML-guide.pdf', 'page': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#了解資料來源\n",
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取網頁資料\n",
    "loader = WebBaseLoader(\"http://google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google搜尋 圖片 地圖 Play YouTube 新聞 Gmail 雲端硬碟 更多 »網頁記錄 | 設定 | 登入 進階搜尋Google 提供：  English 廣告商業解決方案關於 GoogleGoogle.com.tw© 2024 - 隱私權 - 服務條款  \n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"searchParameters\":{\"q\":\"apple inc\",\"hl\":\"zh-tw\",\"type\":\"news\",\"engine\":\"google\"},\"news\":[{\"title\":\"Is Apple Inc. (AAPL) the Best Kid-friendly Stock to Buy Right Now?\",\"link\":\"https://finance.yahoo.com/news/apple-inc-aapl-best-kid-175848382.html\",\"snippet\":\"We recently compiled a list of the 10 Best Kid-Friendly Stocks To Buy Right Now. In this article, we are going to take a look at where Apple...\",\"date\":\"18 小時前\",\"source\":\"Yahoo Finance\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRqs3Ew-dTK28r3XdWgkrPRm-JtIU5tkqmRPSuzlUE1blx3MPEQ9CcevfvDkg&s\",\"position\":1},{\"title\":\"Apple Inc. stock outperforms competitors on strong trading day\",\"link\":\"https://www.marketwatch.com/data-news/apple-inc-stock-outperforms-competitors-on-strong-trading-day-d3d380d6-9bde2aa95ecc\",\"snippet\":\"inched 0.32% higher to $259.02 Thursday, on what proved to be an all-around mixed trading session for the stock market, with the Dow Jones...\",\"date\":\"2 天前\",\"source\":\"MarketWatch\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTlSkpFJdUdaRMlroj4TAaUo2_sceSyfqkCEeOx8vCL1l_fRoukfamsF97Wiw&s\",\"position\":2},{\"title\":\"Apple Teases Streaming 'See For Yourself' Event: Could This Be A Free Preview Of AppleTV+ Or Ad-Supported Platform?\",\"link\":\"https://www.benzinga.com/24/12/42709939/apple-teases-streaming-see-for-yourself-event-could-this-be-a-free-preview-of-appletv-or-ad-supported-platform\",\"snippet\":\"Technology giant Apple Inc. AAPL+0.33%. Get Free Report. could have an exciting 2025 ahead, a year that could include something new for its...\",\"date\":\"1 天前\",\"source\":\"Benzinga\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRg-6qu6EzazB8ZRBhRkhRhk43lYvWGwpgC2lFQPTfxUOZpgLX1IZjYXMJuEA&s\",\"position\":3},{\"title\":\"Why this analyst thinks Apple stock has 'a difficult set-up for January'\",\"link\":\"https://www.investing.com/news/stock-market-news/why-this-analyst-thinks-apple-stock-has-a-difficult-setup-for-january-3788960\",\"snippet\":\"Investing.com -- Apple Inc's (NASDAQ:AAPL) recent rally may face turbulence in the new year, according to a note from BTIG.\",\"date\":\"2 天前\",\"source\":\"Investing.com\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTcmbuRXSuqRz7s0mHi3YHPc3bT8YrYj1MOyPVoDYfxBrzOrQCYYpksZ0jLxQ&s\",\"position\":4},{\"title\":\"Apple (AAPL) Ascends While Market Falls: Some Facts to Note\",\"link\":\"https://finance.yahoo.com/news/apple-aapl-ascends-while-market-224521758.html\",\"snippet\":\"Apple (AAPL) concluded the recent trading session at $259.02, signifying a +0.32% move from its prior day's close.\",\"date\":\"2 天前\",\"source\":\"Yahoo Finance\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQbNq5g0NLVxh9_xkI5J874SP5oK-pvbUzIkGGIm9x_Wu6exz_XnZrkpKkq2A&s\",\"position\":5},{\"title\":\"Apple seeks to defend Google's billion-dollar payments in search case\",\"link\":\"https://www.reuters.com/technology/apple-seeks-defend-googles-billion-dollar-payments-search-case-2024-12-24/\",\"snippet\":\"Apple has asked to participate in Google's upcoming U.S. antitrust trial over online search, saying it cannot rely on Google to defend...\",\"date\":\"4 天前\",\"source\":\"Reuters\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcShdKTOAZKTGiI5GczdomngB9_OO4cWeCiKh2cHpwfS7MqYiYTCdtarFJUHOg&s\",\"position\":6},{\"title\":\"\\\"You a**holes\\\" - When Joe Rogan got brutally honest about $6.2 trillion-worth Apple Inc.'s infamous batter-drain controversy\",\"link\":\"https://www.sportskeeda.com/mma/you-a-holes-when-joe-rogan-got-brutally-honest-6-2-trillion-worth-apple-inc-s-infamous-batter-drain-controversy\",\"snippet\":\"Six years ago, episode #1186 of The Joe Rogan Experience welcomed popular tech reviewer Marques Brownlee. During his appearance, Apple Inc.\",\"date\":\"11 小時前\",\"source\":\"Sportskeeda\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRqJFny_emb6GnS_BD8oGwruohhqyuCMVXSNhzlP8enPQ82IK3F3DlNnzwLFg&s\",\"position\":7},{\"title\":\"Apple asks to participate in Google’s upcoming antitrust trial\",\"link\":\"https://siliconangle.com/2024/12/24/apple-asks-participate-googles-upcoming-antitrust-trial/\",\"snippet\":\"Apple Inc. has asked to participate in an upcoming antitrust trial that will focus on Google LLC's practices in the search market.\",\"date\":\"4 天前\",\"source\":\"SiliconANGLE\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRMX3Zzl2FRtF1RIJ1GCJWCQ1oeCwMgImoMWIjhMsNuDHIqy0gMbjLzeoBfTg&s\",\"position\":8},{\"title\":\"Got an Apple computer for Christmas? Here are 6 apps and games to try with that new Mac\",\"link\":\"https://www.fastcompany.com/91242655/apple-computer-for-christmas-apps-games-new-mac-prince-of-persia-pixelmator-timestor-prim-werecleaner-cleanmymac\",\"snippet\":\"Got an Apple computer for the Christmas? Test out your new Mac with these games and apps, from Prince of Persia to Pixelmator to...\",\"date\":\"1 天前\",\"source\":\"Fast Company\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRlx927RSBSOWjHtxw703qPbAfflLLoGQju8JDWSjPbXvqOaim6KwZZCmWtGw&s\",\"position\":9},{\"title\":\"iOS 18\",\"link\":\"https://www.apple.com/ios/ios-18/\",\"snippet\":\"iOS 18 makes iPhone even more personal, with deeper customization, new ways to connect, easier-to-find photos, and support for Apple Intelligence.\",\"date\":\"3 個月前\",\"source\":\"Apple\",\"imageUrl\":\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTRI0TomlSgsglOYP37lY_rzNQn73Q6usMWKIKFWKA4BOwYZvwnVStpyCYpBA&s\",\"position\":10}],\"credits\":1}\n"
     ]
    }
   ],
   "source": [
    "#利用Serper搜尋訊息，並載入\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://google.serper.dev/news\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"q\": \"apple inc\",\n",
    "  \"hl\": \"zh-tw\"\n",
    "})\n",
    "headers = {\n",
    "  'X-API-KEY': 'b4a777328367a49d9e0c287a72c709995c66068f',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Text Splitter文本分割器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=9,      #每個chunk大小(每幾個token切1組chunk)\n",
    "    chunk_overlap=9    #前後chunk重疊的字符\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123456789']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(text1)\n",
    "#剛好9字符沒有分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"123456789123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123456789',\n",
       " '234567891',\n",
       " '345678912',\n",
       " '456789123',\n",
       " '567891234',\n",
       " '678912345',\n",
       " '789123456',\n",
       " '891234567',\n",
       " '912345678',\n",
       " '123456789']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"This is a sample text to split. It has multiple sentences\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a',\n",
       " 'a sample',\n",
       " 'text to',\n",
       " 'split.',\n",
       " 'It has',\n",
       " 'multiple',\n",
       " 'sentence',\n",
       " 'sentences']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x1c5cf5d2fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"./data/ML-guide.pdf\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we'll start to talk a bit about machine learning.  \\nBy way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \\nI personally work in machine learning, and I've worked on it for about 15 years now, and \\nI actually think that machine learning is the \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = loader.load()\n",
    "pages[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]   #分割邏輯(有優先順序性)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分割後，總共分成幾個chunk\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MachineLearning-Lecture01  \\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine \\nlearning class. So what I wanna do today is just spend a little time going over the logistics \\nof the class, and then we'll start to talk a bit about machine learning.  \\nBy way of introduction, my name's Andrew Ng and I'll be instructor for this class. And so \\nI personally work in machine learning, and I've worked on it for about 15 years now, and\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第1組chunk資料\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I personally work in machine learning, and I've worked on it for about 15 years now, and \\nI actually think that machine learning is the most exciting field of all the computer \\nsciences. So I'm actually always excited about teaching this class. Sometimes I actually \\nthink that machine learning is not only the most exciting thing in computer science, but \\nthe most exciting thing in all of human endeavor, so maybe a little bias there.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第2組chunk資料\n",
    "docs[1].page_content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Chunking分塊大小怎麼決定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import ReadTheDocsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取html檔案，可把html的語法濾掉\n",
    "loader = ReadTheDocsLoader(\n",
    "    \"htmldocs\",   #可讀取該目錄下所有html文檔\n",
    "    encoding=\"utf-8\",  # 確保編碼與文件一致\n",
    "    errors=\"ignore\"    # 忽略無法解碼的字符\n",
    ")     \n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain.indexes.vectorstore.VectorstoreIndexCreator¶\n",
      "class langchain.indexes.vectorstore.VectorstoreIndexCreator[source]¶\n",
      "Bases: BaseModel\n",
      "Logic for creating indexes.\n",
      "Create a new model by parsing and validating input data from keyword arguments.\n",
      "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "param embedding: Embeddings [Optional]¶\n",
      "param text_splitter: TextSplitter [Optional]¶\n",
      "param vectorstore_cls: Type[VectorStore] = <class 'langchain_community.vectorstores.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-3.5-turbo 4096 tokens\n",
    "# If 4096 - (Input(Instruction + query + context) + output)\n",
    "#     If Chunk nums = 5:\n",
    "#         Chunk Size = 2000 / 5 = 400      *假設Instruction + query使用2000 tokens\n",
    "\n",
    "# So Chunk Size <= 400\n",
    "\n",
    "# Too small not meaningful\n",
    "# Too big not efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1538, 1605]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token_count(doc.page_content) for doc in docs]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=token_count,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = text_splitter.split_text(docs[0].page_content)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 373, 345, 376, 105)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count(chunks[0]), token_count(chunks[1]), token_count(chunks[2]), token_count(chunks[3]), token_count(chunks[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"langchain.indexes.vectorstore.VectorstoreIndexCreator¶\\nclass langchain.indexes.vectorstore.VectorstoreIndexCreator[source]¶\\nBases: BaseModel\\nLogic for creating indexes.\\nCreate a new model by parsing and validating input data from keyword arguments.\\nRaises ValidationError if the input data cannot be parsed to form a valid model.\\nparam embedding: Embeddings [Optional]¶\\nparam text_splitter: TextSplitter [Optional]¶\\nparam vectorstore_cls: Type[VectorStore] = <class 'langchain_community.vectorstores.inmemory.InMemoryVectorStore'>¶\\nparam vectorstore_kwargs: dict [Optional]¶\\nasync afrom_documents(documents: List[Document]) → VectorStoreIndexWrapper[source]¶\\nCreate a vectorstore index from documents.\\nParameters\\ndocuments (List[Document]) – \\nReturn type\\nVectorStoreIndexWrapper\\nasync afrom_loaders(loaders: List[BaseLoader]) → VectorStoreIndexWrapper[source]¶\\nCreate a vectorstore index from loaders.\\nParameters\\nloaders (List[BaseLoader]) – \\nReturn type\\nVectorStoreIndexWrapper\\nclassmethod construct(_fields_set: Optional[SetStr] = None, **values: Any) → Model¶\\nCreates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\\nDefault values are respected, but no other validation is performed.\\nBehaves as if Config.extra = ‘allow’ was set since it adds all passed values\\nParameters\\n_fields_set (Optional[SetStr]) – \\nvalues (Any) – \\nReturn type\\nModel\\ncopy(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, update: Optional[DictStrAny] = None, deep: bool = False) → Model¶\",\n",
       " 'Duplicate a model, optionally choose which fields to include, exclude and change.\\nParameters\\ninclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to include in new model\\nexclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – fields to exclude from new model, as with values this takes precedence over include\\nupdate (Optional[DictStrAny]) – values to change/add in the new model. Note: the data is not validated before creating\\nthe new model: you should trust this data\\ndeep (bool) – set to True to make a deep copy of the model\\nself (Model) – \\nReturns\\nnew model instance\\nReturn type\\nModel\\ndict(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) → DictStrAny¶\\nGenerate a dictionary representation of the model, optionally specifying which fields to include or exclude.\\nParameters\\ninclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \\nexclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \\nby_alias (bool) – \\nskip_defaults (Optional[bool]) – \\nexclude_unset (bool) – \\nexclude_defaults (bool) – \\nexclude_none (bool) – \\nReturn type\\nDictStrAny\\nfrom_documents(documents: List[Document]) → VectorStoreIndexWrapper[source]¶\\nCreate a vectorstore index from documents.\\nParameters\\ndocuments (List[Document]) – \\nReturn type\\nVectorStoreIndexWrapper',\n",
       " 'Parameters\\ndocuments (List[Document]) – \\nReturn type\\nVectorStoreIndexWrapper\\nfrom_loaders(loaders: List[BaseLoader]) → VectorStoreIndexWrapper[source]¶\\nCreate a vectorstore index from loaders.\\nParameters\\nloaders (List[BaseLoader]) – \\nReturn type\\nVectorStoreIndexWrapper\\nclassmethod from_orm(obj: Any) → Model¶\\nParameters\\nobj (Any) – \\nReturn type\\nModel\\njson(*, include: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, exclude: Optional[Union[AbstractSetIntStr, MappingIntStrAny]] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) → unicode¶\\nGenerate a JSON representation of the model, include and exclude arguments as per dict().\\nencoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps().\\nParameters\\ninclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \\nexclude (Optional[Union[AbstractSetIntStr, MappingIntStrAny]]) – \\nby_alias (bool) – \\nskip_defaults (Optional[bool]) – \\nexclude_unset (bool) – \\nexclude_defaults (bool) – \\nexclude_none (bool) – \\nencoder (Optional[Callable[[Any], Any]]) – \\nmodels_as_dict (bool) – \\ndumps_kwargs (Any) – \\nReturn type\\nunicode',\n",
       " \"dumps_kwargs (Any) – \\nReturn type\\nunicode\\nclassmethod parse_file(path: Union[str, Path], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\\nParameters\\npath (Union[str, Path]) – \\ncontent_type (unicode) – \\nencoding (unicode) – \\nproto (Protocol) – \\nallow_pickle (bool) – \\nReturn type\\nModel\\nclassmethod parse_obj(obj: Any) → Model¶\\nParameters\\nobj (Any) – \\nReturn type\\nModel\\nclassmethod parse_raw(b: Union[str, bytes], *, content_type: unicode = None, encoding: unicode = 'utf8', proto: Protocol = None, allow_pickle: bool = False) → Model¶\\nParameters\\nb (Union[str, bytes]) – \\ncontent_type (unicode) – \\nencoding (unicode) – \\nproto (Protocol) – \\nallow_pickle (bool) – \\nReturn type\\nModel\\nclassmethod schema(by_alias: bool = True, ref_template: unicode = '#/definitions/{model}') → DictStrAny¶\\nParameters\\nby_alias (bool) – \\nref_template (unicode) – \\nReturn type\\nDictStrAny\\nclassmethod schema_json(*, by_alias: bool = True, ref_template: unicode = '#/definitions/{model}', **dumps_kwargs: Any) → unicode¶\\nParameters\\nby_alias (bool) – \\nref_template (unicode) – \\ndumps_kwargs (Any) – \\nReturn type\\nunicode\\nclassmethod update_forward_refs(**localns: Any) → None¶\\nTry to update ForwardRefs on fields based on this Model, globalns and localns.\\nParameters\\nlocalns (Any) – \\nReturn type\\nNone\\nclassmethod validate(value: Any) → Model¶\\nParameters\",\n",
       " 'Return type\\nNone\\nclassmethod validate(value: Any) → Model¶\\nParameters\\nvalue (Any) – \\nReturn type\\nModel\\nExamples using VectorstoreIndexCreator¶\\nCreate a vectorstore retriever from the loader\\nRetrievers\\nSet env var OPENAI_API_KEY or load from a .env file:\\napify.md\\napify_dataset.md\\nhugging_face_dataset.md\\nimage_captions.md\\nsee https://python.langchain.com/en/latest/modules/data_connection/getting_started.html for more details']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
