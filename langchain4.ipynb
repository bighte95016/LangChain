{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 如何使用LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "chat = Ollama(model=\"openchat:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"請回答以下提問: \\n{query}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template,\n",
    "    output_parser=output_parser\n",
    ")\n",
    "\n",
    "output = chain.invoke({\"query\": \"生成式人工智能是什麼?\"})\n",
    "print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat | output_parser   #LCEL\n",
    "\n",
    "output = chain.invoke({\"query\": \"什麼是AI?\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 創建AI智能體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | chat | output_parser   #LCEL\n",
    "\n",
    "output = chain.invoke({\"query\": \"現在幾點?\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用自定義tool\n",
    "import datetime\n",
    "from langchain.agents import tool\n",
    "\n",
    "@tool\n",
    "def check_time(format:str = \"%Y-%m-%d %H:%M:%S\"):\n",
    "    \"\"\"根據指定的格式返回當前日期和時間\"\"\"\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    formatted_time = current_time.strftime(format)\n",
    "\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "# set the LANGCHAIN_API_KEY environment variable (create key in settings)\n",
    "# https://smith.langchain.com/hub/conquereraman/react-chat\n",
    "from langchain import hub\n",
    "prompt_template = hub.pull(\"aixgeek/react4chinese\")\n",
    "\n",
    "tools = [check_time]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm=chat,\n",
    "    tools=tools,\n",
    "    prompt=prompt_template\n",
    ")\n",
    "\n",
    "agent_executer = AgentExecutor(\n",
    "    llm=chat,\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "agent_executer.invoke({\"input\": \"現在幾點?\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 AI Agent如何使用LangChain自帶工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用地端model\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "chat = Ollama(model=\"openchat:latest\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用langchain內建tool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"aixgeek/react4chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(\n",
    "    top_k_results=1,            #最多回傳多少搜尋結果\n",
    "    doc_content_chars_max=500   #最大字符串\n",
    ")\n",
    "\n",
    "wikitool = WikipediaQueryRun(\n",
    "    api_wrapper=api_wrapper\n",
    ")\n",
    "\n",
    "tools = [wikitool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    llm=chat,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executer = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"現任香港特首是誰?\"\n",
    "\n",
    "agent_executer.invoke({\"input\": input})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改使用雲端model: OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改使用雲端model: OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_base=os.environ[\"CHATGPT_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用langchain內建tool\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "#from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor   #改成使用OpenAI創建agent的方式\n",
    "from langchain import hub\n",
    "\n",
    "#prompt = hub.pull(\"aixgeek/react4chinese\")\n",
    "# set the LANGCHAIN_API_KEY environment variable (create key in settings) \n",
    "# https://smith.langchain.com/hub/brianxiadong/openai-functions-agent\n",
    "prompt = hub.pull(\"brianxiadong/openai-functions-agent\")                    #改成使用OpenAI創建agent的prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(\n",
    "    top_k_results=1,            #最多回傳多少搜尋結果\n",
    "    doc_content_chars_max=500   #最大字符串\n",
    ")\n",
    "\n",
    "wikitool = WikipediaQueryRun(\n",
    "    api_wrapper=api_wrapper\n",
    ")\n",
    "\n",
    "tools = [wikitool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(\n",
    "    llm=chat,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executer = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"現任香港特首是誰?\"\n",
    "system = \"請用中文思考與回答問題\"\n",
    "chat_history = []\n",
    "\n",
    "agent_executer.invoke({\"input\": input, \"system\": system, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
