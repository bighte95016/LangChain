{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_base=os.environ[\"CHATGPT_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''text='what is 1+1?'\n",
    "\n",
    "output = chat.invoke(text)\n",
    "print(output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: 什麼庫提供LLM?\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: {query}\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"query\"], \n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"LLM是什麼\"\n",
    "myprompt = prompt_template.format(query = question)\n",
    "print(chat.invoke(myprompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"如下是AI駐守的對話。\n",
    "這位助手比較幽默，對用戶的提問會給出非常有創意和有趣的回應。\n",
    "以下是一些例子:\n",
    "\n",
    "用戶: 你好嗎?\n",
    "AI: 我的感覺很不錯，你呢?\n",
    "\n",
    "用戶: 現在幾點了?\n",
    "AI: 你等等，我要先解鎖我的iphone\n",
    "\n",
    "用戶: 什麼味道的冰淇淋好吃?\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\":\"你好嗎?\",\n",
    "        \"answer\":\"我的感覺不錯，你呢?\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"現在幾點?\",\n",
    "        \"answer\":\"你等等,我要解鎖一下iphone\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"query\", \"answer\"],\n",
    "    template = example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\"\n",
    "    如下是一位AI助手的對話。\n",
    "    他總會用幽默的回覆方式回應用戶。\n",
    "    以下是助手對話的一些例子\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\"\n",
    "    用戶: {userQuery}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = prefix,\n",
    "    suffix = suffix,\n",
    "    input_variables = [\"userQuery\"],\n",
    "    example_separator = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"如何讓生活更加幸福?\"\n",
    "formatted_prompt = few_shot_prompt_template.format(userQuery=answer)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat.invoke(formatted_prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#課程2-9 chain\n",
    "template = \"\"\"\n",
    "    回答如下問題，並說出準確的計算答案\n",
    "\n",
    "    問題: {query}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oputput = chain.invoke({\"query\":\"18的0.6352次方式多少?\"})\n",
    "print(oputput[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_chain = LLMMathChain.from_llm(\n",
    "    llm=chat,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = math_chain.invoke({\"question\":\"18的0.6352次方式多少?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def transform_func(inputs: dict):\n",
    "    text = inputs[\"tr_text\"]\n",
    "\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "\n",
    "    return {\"tr_output\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.transform import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_spaces_chain = TransformChain(\n",
    "    input_variables=[\"tr_text\"],\n",
    "    output_variables=[\"tr_output\"],\n",
    "    transform=transform_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = clean_spaces_chain.invoke({\"tr_text\": \"   Hello                                              World!~                   \"})    \n",
    "\n",
    "print(output[\"tr_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    轉換如下文字:\n",
    "    \n",
    "    {tr_output}\n",
    "    \n",
    "    新形式{cvr_style}\n",
    "    \n",
    "    轉換:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    #input_variables=[\"cvr_output\", \"cvr_style\"],\n",
    "    input_variables=[\"cvr_style\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    output_key=\"new_output\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output = convert_chain.invoke({\"cvr_output\": \"Gong Hey Fat Choy\", \"cvr_style\": \"變中文\"})\n",
    "# print(new_output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(\n",
    "    chains = [clean_spaces_chain, convert_chain],\n",
    "    input_variables=[\"tr_text\", \"cvr_style\"],\n",
    "    output_variables=[\"new_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Gong Hey Fat Choy               is a             traditional                        Cantonese phrase                used to convey          well-wishes during                        the Chinese             New Year celebration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sequential_chain.invoke({\"tr_text\": input_text, \"cvr_style\": \"轉換成中文\"})\n",
    "print(output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-10 記憶(把過去資料存下來，問問題會再丟給LLM)\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有記憶都存下來\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每次都把過去記憶做總結，再存下來\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(llm=chat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation_sum.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以設定要記錄前幾個window的紀錄\n",
    "conversation_buff_win = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferWindowMemory(k=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Youtube實現畫中畫功能嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何做pizza嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
