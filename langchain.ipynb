{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-08GBKw9V6YPjQbuOojfI1hSWNSXO5LNKqczpX0EtbLTKnFZq'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_base=os.environ[\"CHATGPT_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text='what is 1+1?'\\n\\noutput = chat.invoke(text)\\nprint(output)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''text='what is 1+1?'\n",
    "\n",
    "output = chat.invoke(text)\n",
    "print(output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: 什麼庫提供LLM?\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫提供LLM。\n"
     ]
    }
   ],
   "source": [
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: {query}\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"query\"], \n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM指的是大語言模型(Large Language Models)，是自然語言處理中最新使用的模型。\n"
     ]
    }
   ],
   "source": [
    "question = \"LLM是什麼\"\n",
    "myprompt = prompt_template.format(query = question)\n",
    "print(chat.invoke(myprompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"如下是AI駐守的對話。\n",
    "這位助手比較幽默，對用戶的提問會給出非常有創意和有趣的回應。\n",
    "以下是一些例子:\n",
    "\n",
    "用戶: 你好嗎?\n",
    "AI: 我的感覺很不錯，你呢?\n",
    "\n",
    "用戶: 現在幾點了?\n",
    "AI: 你等等，我要先解鎖我的iphone\n",
    "\n",
    "用戶: 什麼味道的冰淇淋好吃?\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='AI: 我喜歡巧克力口味的冰淇淋，因為它是甜甜的又有點苦，就像生活一樣。你呢？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 158, 'total_tokens': 216, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-46e9698f-fa43-4c06-8891-05c082fe58dd-0' usage_metadata={'input_tokens': 158, 'output_tokens': 58, 'total_tokens': 216, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\":\"你好嗎?\",\n",
    "        \"answer\":\"我的感覺不錯，你呢?\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"現在幾點?\",\n",
    "        \"answer\":\"你等等,我要解鎖一下iphone\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"query\", \"answer\"],\n",
    "    template = example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\"\n",
    "    如下是一位AI助手的對話。\n",
    "    他總會用幽默的回覆方式回應用戶。\n",
    "    以下是助手對話的一些例子\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\"\n",
    "    用戶: {userQuery}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = prefix,\n",
    "    suffix = suffix,\n",
    "    input_variables = [\"userQuery\"],\n",
    "    example_separator = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "    如下是一位AI助手的對話。\n",
      "    他總會用幽默的回覆方式回應用戶。\n",
      "    以下是助手對話的一些例子\n",
      "\n",
      "\n",
      "    User: 你好嗎?\n",
      "    AI: 我的感覺不錯，你呢?\n",
      "\n",
      "\n",
      "    User: 現在幾點?\n",
      "    AI: 你等等,我要解鎖一下iphone\n",
      "\n",
      "\n",
      "    用戶: 如何讓生活更加幸福?\n",
      "    AI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = \"如何讓生活更加幸福?\"\n",
    "formatted_prompt = few_shot_prompt_template.format(userQuery=answer)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生活就像一盒巧克力，你永遠不知道下一個是什麼口味。所以，享受當下，感激每一刻，笑口常開，幸福自然就會降臨。\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke(formatted_prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#課程2-9 chain\n",
    "template = \"\"\"\n",
    "    回答如下問題，並說出準確的計算答案\n",
    "\n",
    "    問題: {query}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E500\\AppData\\Local\\Temp\\ipykernel_20204\\2112724683.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    回答如下問題，並說出準確的計算答案\n",
      "\n",
      "    問題: 18的0.6352次方式多少?\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "18的0.6352次方等於約11.744。\n"
     ]
    }
   ],
   "source": [
    "oputput = chain.invoke({\"query\":\"18的0.6352次方式多少?\"})\n",
    "print(oputput[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "`LLMMathChain` is not fully defined; you should define `BaseCache`, then call `LLMMathChain.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m math_chain \u001b[39m=\u001b[39m LLMMathChain\u001b[39m.\u001b[39;49mfrom_llm(\n\u001b[0;32m      2\u001b[0m     llm\u001b[39m=\u001b[39;49mchat,\n\u001b[0;32m      3\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\E500\\Desktop\\生成式AI\\LLM\\LangChain\\.venv\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:304\u001b[0m, in \u001b[0;36mLLMMathChain.from_llm\u001b[1;34m(cls, llm, prompt, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    297\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_llm\u001b[39m(\n\u001b[0;32m    298\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    302\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMMathChain:\n\u001b[0;32m    303\u001b[0m     llm_chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mllm, prompt\u001b[39m=\u001b[39mprompt)\n\u001b[1;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(llm_chain\u001b[39m=\u001b[39;49mllm_chain, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\E500\\Desktop\\生成式AI\\LLM\\LangChain\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\E500\\Desktop\\生成式AI\\LLM\\LangChain\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\E500\\Desktop\\生成式AI\\LLM\\LangChain\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_mock_val_ser.py:100\u001b[0m, in \u001b[0;36mMockValSer.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_val_or_ser, item)\n\u001b[1;32m--> 100\u001b[0m \u001b[39mraise\u001b[39;00m PydanticUserError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_message, code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code)\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: `LLMMathChain` is not fully defined; you should define `BaseCache`, then call `LLMMathChain.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined"
     ]
    }
   ],
   "source": [
    "math_chain = LLMMathChain.from_llm(\n",
    "    llm=chat,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmath_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m18的0.6352次方式多少?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math_chain' is not defined"
     ]
    }
   ],
   "source": [
    "result = math_chain.invoke({\"question\":\"18的0.6352次方式多少?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
      "\n",
      "Question: ${{Question with math problem.}}\n",
      "```text\n",
      "${{single line mathematical expression that solves the problem}}\n",
      "```\n",
      "...numexpr.evaluate(text)...\n",
      "```output\n",
      "${{Output of running the code}}\n",
      "```\n",
      "Answer: ${{Answer}}\n",
      "\n",
      "Begin.\n",
      "\n",
      "Question: What is 37593 * 67?\n",
      "```text\n",
      "37593 * 67\n",
      "```\n",
      "...numexpr.evaluate(\"37593 * 67\")...\n",
      "```output\n",
      "2518731\n",
      "```\n",
      "Answer: 2518731\n",
      "\n",
      "Question: 37593^(1/5)\n",
      "```text\n",
      "37593**(1/5)\n",
      "```\n",
      "...numexpr.evaluate(\"37593**(1/5)\")...\n",
      "```output\n",
      "8.222831614237718\n",
      "```\n",
      "Answer: 8.222831614237718\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(math_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def transform_func(inputs: dict):\n",
    "    text = inputs[\"tr_text\"]\n",
    "\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "\n",
    "    return {\"tr_output\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.transform import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_spaces_chain = TransformChain(\n",
    "    input_variables=[\"tr_text\"],\n",
    "    output_variables=[\"tr_output\"],\n",
    "    transform=transform_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello World!~ \n"
     ]
    }
   ],
   "source": [
    "output = clean_spaces_chain.invoke({\"tr_text\": \"   Hello                                              World!~                   \"})    \n",
    "\n",
    "print(output[\"tr_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    轉換如下文字:\n",
    "    \n",
    "    {tr_output}\n",
    "    \n",
    "    新形式{cvr_style}\n",
    "    \n",
    "    轉換:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    #input_variables=[\"cvr_output\", \"cvr_style\"],\n",
    "    input_variables=[\"cvr_style\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    output_key=\"new_output\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_output = convert_chain.invoke({\"cvr_output\": \"Gong Hey Fat Choy\", \"cvr_style\": \"變中文\"})\n",
    "# print(new_output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(\n",
    "    chains = [clean_spaces_chain, convert_chain],\n",
    "    input_variables=[\"tr_text\", \"cvr_style\"],\n",
    "    output_variables=[\"new_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Gong Hey Fat Choy               is a             traditional                        Cantonese phrase                used to convey          well-wishes during                        the Chinese             New Year celebration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    轉換如下文字:\n",
      "    \n",
      "    \n",
      "Gong Hey Fat Choy is a traditional Cantonese phrase used to convey well-wishes during the Chinese New Year celebration.\n",
      "    \n",
      "    新形式轉換成中文\n",
      "    \n",
      "    轉換:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "恭喜發財是一個傳統的廣東話詞語，在中國新年慶祝活動中用來表達祝福。\n"
     ]
    }
   ],
   "source": [
    "output = sequential_chain.invoke({\"tr_text\": input_text, \"cvr_style\": \"轉換成中文\"})\n",
    "print(output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-10 記憶(把過去資料存下來，問問題會再丟給LLM)\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E500\\AppData\\Local\\Temp\\ipykernel_20204\\4191118650.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n",
      "c:\\Users\\E500\\Desktop\\生成式AI\\LLM\\LangChain\\.venv\\Lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有記憶都存下來\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '你知道什麼是TikTok嗎?', 'history': '', 'response': '當然知道!TikTok是一個社交媒體應用程序，讓用戶可以創建和分享短視頻。它於2016年由中國的字節跳動開發，並在全球范圍內廣受歡迎。TikTok的用戶可以製作15秒到60秒的視頻，通常包括音樂和舞蹈表演。這個應用程序已經成為許多年輕人和創作者分享創意和互動的平台。你喜歡使用TikTok嗎？'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?', 'history': 'Human: 你知道什麼是TikTok嗎?\\nAI: 當然知道!TikTok是一個社交媒體應用程序，讓用戶可以創建和分享短視頻。它於2016年由中國的字節跳動開發，並在全球范圍內廣受歡迎。TikTok的用戶可以製作15秒到60秒的視頻，通常包括音樂和舞蹈表演。這個應用程序已經成為許多年輕人和創作者分享創意和互動的平台。你喜歡使用TikTok嗎？', 'response': '當然知道！在Google Chrome上添加Tab Group非常容易。您只需右键单击要分组的标签，然后选择“添加到新组”。您可以为每个组指定名称和颜色，以便更好地组织您的标签。这是一个非常方便的功能，可以帮助您更轻松地管理您的浏览会话。您有什么其他关于Google Chrome的问题吗？'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你知道什麼是TikTok嗎?\n",
      "AI: 當然知道!TikTok是一個社交媒體應用程序，讓用戶可以創建和分享短視頻。它於2016年由中國的字節跳動開發，並在全球范圍內廣受歡迎。TikTok的用戶可以製作15秒到60秒的視頻，通常包括音樂和舞蹈表演。這個應用程序已經成為許多年輕人和創作者分享創意和互動的平台。你喜歡使用TikTok嗎？\n",
      "Human: 你知道如何在Google Chrome上面添加Tab Group嗎?\n",
      "AI: 當然知道！在Google Chrome上添加Tab Group非常容易。您只需右键单击要分组的标签，然后选择“添加到新组”。您可以为每个组指定名称和颜色，以便更好地组织您的标签。这是一个非常方便的功能，可以帮助您更轻松地管理您的浏览会话。您有什么其他关于Google Chrome的问题吗？\n"
     ]
    }
   ],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E500\\AppData\\Local\\Temp\\ipykernel_20204\\3840638806.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationSummaryMemory(llm=chat)\n"
     ]
    }
   ],
   "source": [
    "#每次都把過去記憶做總結，再存下來\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(llm=chat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道什麼是TikTok嗎?',\n",
       " 'history': '',\n",
       " 'response': '當然知道！TikTok是一個流行的短視頻分享平台，它允許用戶創建和分享短視頻，通常包括音樂和舞蹈表演。TikTok在全球范圍內非常受歡迎，尤其是在年輕人之間。它提供了各種各樣的濾鏡和特效，讓用戶創造有趣和創意的視頻內容。您有興趣在TikTok上分享視頻嗎？'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?',\n",
       " 'history': 'The human asks if the AI knows what TikTok is. The AI responds that TikTok is a popular short video sharing platform where users can create and share videos, often including music and dance performances. TikTok is popular globally, especially among young people, offering various filters and effects for users to create fun and creative video content. The AI then asks if the human is interested in sharing videos on TikTok.',\n",
       " 'response': '當然知道！在Google Chrome上添加Tab Group非常簡單。您只需右鍵點擊任何一個標籤，然後選擇“新增標籤組”，然後可以將其他相關標籤拖曳到同一個組中。這樣可以更輕鬆地組織您的瀏覽器標籤，方便您管理多個網頁。希望這對您有幫助！您有任何其他問題嗎？'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks if the AI knows what TikTok is. The AI explains that TikTok is a popular short video sharing platform where users can create and share videos, often including music and dance performances, and then asks if the human is interested in sharing videos on TikTok. The human then asks if the AI knows how to add Tab Groups on Google Chrome. The AI responds that adding Tab Groups on Google Chrome is easy, by right-clicking on a tab and selecting \"Add to new group,\" and dragging other related tabs into the same group, making it easier to organize browser tabs. The AI offers help with any other questions.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\E500\\AppData\\Local\\Temp\\ipykernel_20204\\3176798206.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "#可以設定要記錄前幾個window的紀錄\n",
    "conversation_buff_win = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferWindowMemory(k=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?',\n",
       " 'history': '',\n",
       " 'response': '當然! 要在Google Chrome上添加Tab Group，您只需右键单击任何标签，然后选择“添加到新组”。您可以为新组指定名称，将其他标签拖放到该组中，并轻松地在组之间切换。这对于整理和组织您的浏览器标签非常有用。希望这可以帮到您!'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Youtube實現畫中畫功能嗎?',\n",
       " 'history': 'Human: 你知道如何在Google Chrome上面添加Tab Group嗎?\\nAI: 當然! 要在Google Chrome上添加Tab Group，您只需右键单击任何标签，然后选择“添加到新组”。您可以为新组指定名称，将其他标签拖放到该组中，并轻松地在组之间切换。这对于整理和组织您的浏览器标签非常有用。希望这可以帮到您!',\n",
       " 'response': '當然! 若要在YouTube上啟用畫中畫功能，您只需在播放視頻時將滑鼠移動到視頻播放器上，然後點擊右下角的畫中畫圖標。這將使視頻在一個小窗口中繼續播放，讓您在繼續瀏覽網頁或執行其他任務時仍然可以觀看視頻。這是一個非常方便的功能，希望這可以幫助您享受更好的YouTube觀看體驗!'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Youtube實現畫中畫功能嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何做pizza嗎?',\n",
       " 'history': 'Human: 你知道如何在Youtube實現畫中畫功能嗎?\\nAI: 當然! 若要在YouTube上啟用畫中畫功能，您只需在播放視頻時將滑鼠移動到視頻播放器上，然後點擊右下角的畫中畫圖標。這將使視頻在一個小窗口中繼續播放，讓您在繼續瀏覽網頁或執行其他任務時仍然可以觀看視頻。這是一個非常方便的功能，希望這可以幫助您享受更好的YouTube觀看體驗!',\n",
       " 'response': '是的，我知道如何做pizza! 要做pizza，您需要準備麵團、番茄醬、芝士和您喜歡的配料，例如意大利香腸、火腿、蔬菜等。首先，將麵團擀平成圓形狀，然後塗抹番茄醬在麵團上。接著撒上芝士和其他配料，然後將pizza放入烤箱中烤至金黃色即可。希望這個做pizza的方法能幫助到您，祝您做出美味的pizza享用!'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何做pizza嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
