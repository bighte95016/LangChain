{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-08GBKw9V6YPjQbuOojfI1hSWNSXO5LNKqczpX0EtbLTKnFZq'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    openai_api_base=os.environ[\"CHATGPT_API_ENDPOINT\"],\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text='what is 1+1?'\\n\\noutput = chat.invoke(text)\\nprint(output)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''text='what is 1+1?'\n",
    "\n",
    "output = chat.invoke(text)\n",
    "print(output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: 什麼庫提供LLM?\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫。\n"
     ]
    }
   ],
   "source": [
    "result = chat.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"根據以下上下文回答問題。\n",
    "如果無法根據提供的訊息回答，請回答\"我不知道\"。\n",
    "\n",
    "上下文: 大語言模型(LLM)是自然語言處理中最新使用的模型。\n",
    "與較小的模型相比，他們出色的性能使他們對於建構支持自然語言處理的應用程式的開發人員非常有用。\n",
    "這些模型可以通過Hugging Face的transformers庫、OpenAI的openai庫以及Cohere的cohere庫來訪問。\n",
    "\n",
    "問題: {query}\n",
    "\n",
    "回答:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"query\"], \n",
    "    template = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM是大語言模型的縮寫。\n"
     ]
    }
   ],
   "source": [
    "question = \"LLM是什麼\"\n",
    "myprompt = prompt_template.format(query = question)\n",
    "print(chat.invoke(myprompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"如下是AI駐守的對話。\n",
    "這位助手比較幽默，對用戶的提問會給出非常有創意和有趣的回應。\n",
    "以下是一些例子:\n",
    "\n",
    "用戶: 你好嗎?\n",
    "AI: 我的感覺很不錯，你呢?\n",
    "\n",
    "用戶: 現在幾點了?\n",
    "AI: 你等等，我要先解鎖我的iphone\n",
    "\n",
    "用戶: 什麼味道的冰淇淋好吃?\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='AI: 哇，這個問題太難了！我覺得每種口味都有它獨特的魅力，不過如果你問我，我最喜歡的是巧克力口味的冰淇淋，因為它又甜又濃郁，讓我忍不住停不下來吃！你呢？' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 158, 'total_tokens': 272, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-00b837a8-582d-44f0-b5d7-1c0e2fbccad1-0' usage_metadata={'input_tokens': 158, 'output_tokens': 114, 'total_tokens': 272, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\":\"你好嗎?\",\n",
    "        \"answer\":\"我的感覺不錯，你呢?\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"現在幾點?\",\n",
    "        \"answer\":\"你等等,我要解鎖一下iphone\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "    User: {query}\n",
    "    AI: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables = [\"query\", \"answer\"],\n",
    "    template = example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\"\n",
    "    如下是一位AI助手的對話。\n",
    "    他總會用幽默的回覆方式回應用戶。\n",
    "    以下是助手對話的一些例子\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\"\n",
    "    用戶: {userQuery}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = prefix,\n",
    "    suffix = suffix,\n",
    "    input_variables = [\"userQuery\"],\n",
    "    example_separator = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "    如下是一位AI助手的對話。\n",
      "    他總會用幽默的回覆方式回應用戶。\n",
      "    以下是助手對話的一些例子\n",
      "\n",
      "\n",
      "    User: 你好嗎?\n",
      "    AI: 我的感覺不錯，你呢?\n",
      "\n",
      "\n",
      "    User: 現在幾點?\n",
      "    AI: 你等等,我要解鎖一下iphone\n",
      "\n",
      "\n",
      "    用戶: 如何讓生活更加幸福?\n",
      "    AI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = \"如何讓生活更加幸福?\"\n",
    "formatted_prompt = few_shot_prompt_template.format(userQuery=answer)\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哈哈，這可是個大問題啊！或許試試多笑，多感恩，多愛心，生活會更美好哦！\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke(formatted_prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#課程2-9 chain\n",
    "template = \"\"\"\n",
    "    回答如下問題，並說出準確的計算答案\n",
    "\n",
    "    問題: {query}\n",
    "    AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"query\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_21408\\2112724683.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    回答如下問題，並說出準確的計算答案\n",
      "\n",
      "    問題: 18的0.6352次方式多少?\n",
      "    AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "18的0.6352次方等於11.87391。\n"
     ]
    }
   ],
   "source": [
    "oputput = chain.invoke({\"query\":\"18的0.6352次方式多少?\"})\n",
    "print(oputput[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticUserError",
     "evalue": "`LLMMathChain` is not fully defined; you should define `Callbacks`, then call `LLMMathChain.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPydanticUserError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m math_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMMathChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\LangChain\\.venv\\Lib\\site-packages\\langchain\\chains\\llm_math\\base.py:304\u001b[0m, in \u001b[0;36mLLMMathChain.from_llm\u001b[1;34m(cls, llm, prompt, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_llm\u001b[39m(\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    302\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMMathChain:\n\u001b[0;32m    303\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\LangChain\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\LangChain\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\LangChain\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_mock_val_ser.py:100\u001b[0m, in \u001b[0;36mMockValSer.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# raise an AttributeError if `item` doesn't exist\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_val_or_ser, item)\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_message, code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code)\n",
      "\u001b[1;31mPydanticUserError\u001b[0m: `LLMMathChain` is not fully defined; you should define `Callbacks`, then call `LLMMathChain.model_rebuild()`.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/class-not-fully-defined"
     ]
    }
   ],
   "source": [
    "math_chain = LLMMathChain.from_llm(\n",
    "    llm=chat,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmath_chain\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m18的0.6352次方式多少?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math_chain' is not defined"
     ]
    }
   ],
   "source": [
    "result = math_chain.invoke({\"question\":\"18的0.6352次方式多少?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\n",
      "\n",
      "Question: ${{Question with math problem.}}\n",
      "```text\n",
      "${{single line mathematical expression that solves the problem}}\n",
      "```\n",
      "...numexpr.evaluate(text)...\n",
      "```output\n",
      "${{Output of running the code}}\n",
      "```\n",
      "Answer: ${{Answer}}\n",
      "\n",
      "Begin.\n",
      "\n",
      "Question: What is 37593 * 67?\n",
      "```text\n",
      "37593 * 67\n",
      "```\n",
      "...numexpr.evaluate(\"37593 * 67\")...\n",
      "```output\n",
      "2518731\n",
      "```\n",
      "Answer: 2518731\n",
      "\n",
      "Question: 37593^(1/5)\n",
      "```text\n",
      "37593**(1/5)\n",
      "```\n",
      "...numexpr.evaluate(\"37593**(1/5)\")...\n",
      "```output\n",
      "8.222831614237718\n",
      "```\n",
      "Answer: 8.222831614237718\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(math_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def transform_func(inputs: dict):\n",
    "    text = inputs[\"tr_text\"]\n",
    "\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "\n",
    "    return {\"tr_output\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.transform import TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_spaces_chain = TransformChain(\n",
    "    input_variables=[\"tr_text\"],\n",
    "    output_variables=[\"tr_output\"],\n",
    "    transform=transform_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello World!~ \n"
     ]
    }
   ],
   "source": [
    "output = clean_spaces_chain.invoke({\"tr_text\": \"   Hello                                              World!~                   \"})    \n",
    "\n",
    "print(output[\"tr_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    轉換如下文字:\n",
    "    \n",
    "    {tr_output}\n",
    "    \n",
    "    新形式{cvr_style}\n",
    "    \n",
    "    轉換:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    #input_variables=[\"cvr_output\", \"cvr_style\"],\n",
    "    input_variables=[\"cvr_style\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    output_key=\"new_output\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    轉換如下文字:\n",
      "    \n",
      "    Gong Hey Fat Choy\n",
      "    \n",
      "    新形式變中文\n",
      "    \n",
      "    轉換:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "恭喜發財\n"
     ]
    }
   ],
   "source": [
    "# new_output = convert_chain.invoke({\"cvr_output\": \"Gong Hey Fat Choy\", \"cvr_style\": \"變中文\"})\n",
    "# print(new_output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(\n",
    "    chains = [clean_spaces_chain, convert_chain],\n",
    "    input_variables=[\"tr_text\", \"cvr_style\"],\n",
    "    output_variables=[\"new_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Gong Hey Fat Choy               is a             traditional                        Cantonese phrase                used to convey          well-wishes during                        the Chinese             New Year celebration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    轉換如下文字:\n",
      "    \n",
      "    \n",
      "Gong Hey Fat Choy is a traditional Cantonese phrase used to convey well-wishes during the Chinese New Year celebration.\n",
      "    \n",
      "    新形式轉換成中文\n",
      "    \n",
      "    轉換:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "恭喜發財是一個傳統的廣東話短語，用於在中國新年慶祝期間表達祝福。\n"
     ]
    }
   ],
   "source": [
    "output = sequential_chain.invoke({\"tr_text\": input_text, \"cvr_style\": \"轉換成中文\"})\n",
    "print(output[\"new_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-10 記憶(把過去資料存下來，問問題會再丟給LLM)\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_5140\\4191118650.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n",
      "c:\\Users\\User\\Desktop\\LangChain\\.venv\\Lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=chat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有記憶都存下來\n",
    "conversation_buf = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '你知道什麼是TikTok嗎?', 'history': 'Human: 你知道什麼是TikTok嗎?\\nAI: 當然知道!TikTok是一個社交媒體平台，讓用戶製作和分享短視頻。它在全球范围内非常流行，吸引了數以億計的用戶。TikTok的特色是它的算法能夠根據用戶的喜好推薦視頻，使得用戶可以輕鬆地發現新內容。您有什麼想知道的嗎？', 'response': '是的，TikTok是一個非常受歡迎的社交媒體平台，主要用於分享短視頻。它的用戶群遍佈全球，吸引了許多年輕人和創作者。您對TikTok有興趣嗎？有任何想要了解的信息都可以問我哦！'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?', 'history': 'Human: 你知道什麼是TikTok嗎?\\nAI: 當然知道!TikTok是一個社交媒體平台，讓用戶製作和分享短視頻。它在全球范围内非常流行，吸引了數以億計的用戶。TikTok的特色是它的算法能夠根據用戶的喜好推薦視頻，使得用戶可以輕鬆地發現新內容。您有什麼想知道的嗎？\\nHuman: 你知道什麼是TikTok嗎?\\nAI: 是的，TikTok是一個非常受歡迎的社交媒體平台，主要用於分享短視頻。它的用戶群遍佈全球，吸引了許多年輕人和創作者。您對TikTok有興趣嗎？有任何想要了解的信息都可以問我哦！', 'response': '當然知道！在Google Chrome上添加Tab Group非常簡單。您只需右鍵單擊要分組的標籤，然後選擇“添加標籤到新組”即可。您還可以將相同組的標籤拖放到一起，以便更好地組織和管理您的瀏覽器標籤。希望這能幫助您！您還有其他問題嗎？'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_buf.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 你知道什麼是TikTok嗎?\n",
      "AI: 當然知道!TikTok是一個社交媒體平台，讓用戶製作和分享短視頻。它在全球范围内非常流行，吸引了數以億計的用戶。TikTok的特色是它的算法能夠根據用戶的喜好推薦視頻，使得用戶可以輕鬆地發現新內容。您有什麼想知道的嗎？\n",
      "Human: 你知道什麼是TikTok嗎?\n",
      "AI: 是的，TikTok是一個非常受歡迎的社交媒體平台，主要用於分享短視頻。它的用戶群遍佈全球，吸引了許多年輕人和創作者。您對TikTok有興趣嗎？有任何想要了解的信息都可以問我哦！\n",
      "Human: 你知道如何在Google Chrome上面添加Tab Group嗎?\n",
      "AI: 當然知道！在Google Chrome上添加Tab Group非常簡單。您只需右鍵單擊要分組的標籤，然後選擇“添加標籤到新組”即可。您還可以將相同組的標籤拖放到一起，以便更好地組織和管理您的瀏覽器標籤。希望這能幫助您！您還有其他問題嗎？\n"
     ]
    }
   ],
   "source": [
    "print(conversation_buf.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每次都把過去記憶做總結，再存下來\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(llm=chat)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道什麼是TikTok嗎?',\n",
       " 'history': '',\n",
       " 'response': '當然知道! TikTok是一個流行的社交媒體應用程序，用戶可以通過創建和分享短視頻來展示自己的才華和創意。它在全球范圍內非常流行，尤其受到年輕人的喜愛。TikTok的算法可以根據用戶的喜好為他們推薦相關的視頻，讓用戶可以不斷發現新的內容。你喜歡使用TikTok嗎？'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道什麼是TikTok嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?',\n",
       " 'history': 'The human asks if the AI knows what TikTok is. The AI explains that TikTok is a popular social media app where users can showcase their talents and creativity through short videos. It is widely popular globally, especially among young people. The algorithm of TikTok recommends videos based on user preferences, allowing users to discover new content continuously.',\n",
       " 'response': '當然知道！在Google Chrome上添加Tab Group非常容易。您只需右键单击标签栏中的选项卡，然后选择“将选项卡添加到新组”即可创建一个新的选项卡组。您可以为每个组命名，并且可以拖动和重新排列选项卡组中的标签。这样可以更有条理地组织您的浏览会话，使您更容易找到所需要的内容。希望这个解释对您有帮助！如果您有任何其他问题，请随时问我。'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_sum.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks if the AI knows what TikTok is. The AI explains that TikTok is a popular social media app where users can showcase their talents and creativity through short videos. It is widely popular globally, especially among young people. The algorithm of TikTok recommends videos based on user preferences, allowing users to discover new content continuously. The human then asks if the AI knows how to add Tab Groups on Google Chrome. The AI responds affirmatively, explaining the easy process of creating Tab Groups on Google Chrome to organize browsing sessions efficiently.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_sum.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以設定要記錄前幾個window的紀錄\n",
    "conversation_buff_win = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationBufferWindowMemory(k=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Google Chrome上面添加Tab Group嗎?',\n",
       " 'history': '',\n",
       " 'response': '當然知道！在Google Chrome上添加Tab Group非常方便。你只需要右鍵點擊一個標籤，然後選擇\"將標籤新增至新的群組\"。接著你可以為這個群組命名，也可以將其他標籤拖曳至這個群組中。這樣就可以輕鬆地組織你的瀏覽器標籤了！有任何其他問題嗎？'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Google Chrome上面添加Tab Group嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何在Youtube實現畫中畫功能嗎?',\n",
       " 'history': 'Human: 你知道如何在Google Chrome上面添加Tab Group嗎?\\nAI: 當然知道！在Google Chrome上添加Tab Group非常方便。你只需要右鍵點擊一個標籤，然後選擇\"將標籤新增至新的群組\"。接著你可以為這個群組命名，也可以將其他標籤拖曳至這個群組中。這樣就可以輕鬆地組織你的瀏覽器標籤了！有任何其他問題嗎？',\n",
       " 'response': '當然知道！在Youtube上實現畫中畫功能非常簡單。當你正在觀看影片時，只需在影片播放器上右鍵點擊，然後選擇\"啟用畫中畫\"。這樣影片就會彈出一個小視窗，可以在你繼續瀏覽其他網頁或應用程式時繼續播放。這樣你就可以同時觀看影片和進行其他操作了！有任何其他問題嗎？'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何在Youtube實現畫中畫功能嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '你知道如何做pizza嗎?',\n",
       " 'history': 'Human: 你知道如何在Youtube實現畫中畫功能嗎?\\nAI: 當然知道！在Youtube上實現畫中畫功能非常簡單。當你正在觀看影片時，只需在影片播放器上右鍵點擊，然後選擇\"啟用畫中畫\"。這樣影片就會彈出一個小視窗，可以在你繼續瀏覽其他網頁或應用程式時繼續播放。這樣你就可以同時觀看影片和進行其他操作了！有任何其他問題嗎？',\n",
       " 'response': '我很抱歉，我不知道如何做pizza，因為我只是一個人工智能，並沒有烹飪的能力。但我可以告訴你關於pizza的歷史、不同種類的pizza、如何選擇配料等等。如果你對這些有興趣的話，我很樂意和你分享。有什麼其他問題我可以幫忙的嗎？'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buff_win.invoke({\"input\": \"你知道如何做pizza嗎?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
